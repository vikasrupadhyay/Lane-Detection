{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import cv2\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import PIL\n",
    "import argparse\n",
    "import random\n",
    "import Augmentor\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Lane_detection_using_pretrained_resnet18')\n",
    "# parser.add_argument('--batch_size', type=int, default=4, metavar='B',\n",
    "#                     help='input batch size for training (default: 4)')\n",
    "# parser.add_argument('--test_batch_size', type=int, default=4, metavar='TB',\n",
    "#                     help='input batch size for testing (default: 4)')\n",
    "# parser.add_argument('--epochs', type=int, default=10, metavar='E',\n",
    "#                     help='number of epochs to train (default: 10)')\n",
    "# parser.add_argument('--lr', type=float, default=0.006, metavar='LR',\n",
    "#                     help='learning rate (default: 0.006)')\n",
    "\n",
    "# parser.add_argument('--valid_set_size', type=float, default=0.4, metavar='VSS',\n",
    "#                     help='validation set size (default: 0.4 so 4 % of all the batchs)')\n",
    "\n",
    "\n",
    "# parser.add_argument('--rot', type=int, default=0, metavar='RO',\n",
    "#                     help='1 for augmentation by rotation')\n",
    "# #setting Blurring for default augmentation\n",
    "# parser.add_argument('--gb', type=int, default=1, metavar='GB',\n",
    "#                     help='1 for augmentation by Gaussian Blurring')\n",
    "\n",
    "# parser.add_argument('--spk', type=int, default=0, metavar='SN',\n",
    "#                     help='1 for augmentation by Speckle Noise')\n",
    "\n",
    "# parser.add_argument('--isw', type=int, default=0, metavar='ISW',\n",
    "#                     help='1 for augmentation by Image Segmentation using watershed')\n",
    "\n",
    "# parser.add_argument('--shr', type=int, default=0, metavar='SH',\n",
    "#                     help='1 for augmentation by Shear')\n",
    "\n",
    "\n",
    "\n",
    "# parser.add_argument('--prob', type=float, default=0.5, metavar='PR',\n",
    "#                     help='Enter value between 0 and 1 for the probability by which augmentation is performed')\n",
    "\n",
    "\n",
    "# parser.add_argument('--noaug', type=int, default=1, metavar='NA',\n",
    "#                     help='Enter 0 for no Augmentation at all')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LATENT_DIM = 5 #size of the latent space in the variational autoencoder\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for displaying images\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "class KittiDataset(Dataset):\n",
    "    def __init__(self, directory, augment = False, transform=True):\n",
    "        directory = directory + \"/*.png\"\n",
    "        self.img_names = list(glob.glob(directory))\n",
    "        # print (self.img_names)\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        # self.p = Augmentor.Pipeline(directory)\n",
    "        # self.p.random_distortion(probability=1, grid_width=4, grid_height=4, magnitude=8)\n",
    "        # self.p.flip_left_right(probability=0.5)\n",
    "        # self.p.flip_top_bottom(probability=0.5)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "#         args = parser.parse_args()\n",
    "\n",
    "        path = self.img_names[idx]\n",
    "        image = cv2.imread(path)\n",
    "#         print (\"epoch\")\n",
    "\n",
    "        newHeight = 1200\n",
    "        newWidth = 300\n",
    "        # oldHeight = image.shape[0]\n",
    "        # oldWidth = image.shape[1]\n",
    "        # r = newHeight / oldHeight\n",
    "        # newWidth = int(oldWidth * r)\n",
    "        dim = (newHeight, newWidth)\n",
    "        image = cv2.resize(image, dim,3, interpolation = cv2.INTER_AREA)\n",
    "        # image = image.transpose(1,3)\n",
    "        image_label = 0\n",
    "        # print (\"works\")\n",
    "        if 'uu_' in path:\n",
    "            image_label = 0\n",
    "        elif 'umm_' in path:\n",
    "            image_label = 1\n",
    "        elif 'um_' in path:\n",
    "            image_label = 2\n",
    "        else:\n",
    "            print (\" error in label\")\n",
    "            image_label = 2\n",
    "#         if self.augment:\n",
    "\n",
    "#             prob = args.prob\n",
    "\n",
    "#             if prob <0 or prob >1:\n",
    "#                 prob =0.5\n",
    "\n",
    "#             #rotation of image \n",
    "#             row,col,ch = 1200,300,3\n",
    "#             cv2.imwrite('image.png',image)\n",
    "#             if args.rot == 1 and np.random.uniform(0,1) > prob:\n",
    "#                 angle = random.randint(1,80)\n",
    "#                 M = cv2.getRotationMatrix2D((300/2,1200/2),angle,1)\n",
    "#                 image = cv2.warpAffine(image.copy(),M,(300,1200))\n",
    "#             \"\"\"*********************************************\"\"\"\n",
    "#             if args.gb == 1 and np.random.uniform(0,1) > prob:\n",
    "#             #Gaussian Blurring\n",
    "\n",
    "#                 image = cv2.GaussianBlur(image,(5,5),0)\n",
    "\n",
    "\n",
    "#             \"\"\"*********************************************\"\"\"\n",
    "#             #Segmentation algorithm using watershed\n",
    "#             if args.isw == 1 and np.random.uniform(0,1) > prob:\n",
    "\n",
    "#                 gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#                 ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "#                 # noise removal\n",
    "#                 kernel = np.ones((3,3),np.uint8)\n",
    "#                 opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "#                 # sure background area\n",
    "#                 sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "#                 # Finding sure foreground area\n",
    "#                 dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "#                 ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "#                 # Finding unknown region\n",
    "#                 sure_fg = np.uint8(sure_fg)\n",
    "#                 unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "#                 # Marker labelling\n",
    "#                 ret, markers = cv2.connectedComponents(sure_fg)\n",
    "#                 # Add one to all labels so that sure background is not 0, but 1\n",
    "#                 markers = markers+1\n",
    "#                 # Now, mark the region of unknown with zero\n",
    "#                 markers[unknown==255] = 0\n",
    "\n",
    "#                 markers = cv2.watershed(image,markers)\n",
    "#                 image[markers == -1] = [255,0,0]\n",
    "#                 cv2.imwrite('Segmentation.png',image)\n",
    "\n",
    "#             \"\"\"*********************************************\"\"\"\n",
    "\n",
    "#             #speckle noise\n",
    "\n",
    "#             if args.spk == 1 and np.random.uniform(0,1) > prob:\n",
    "#                 row,col,ch = 1200,300,3\n",
    "#                 gauss = np.random.randn(row,col,ch)\n",
    "#                 gauss = gauss.reshape(row,col,ch)        \n",
    "#                 image = image + image * gauss\n",
    "\n",
    "\n",
    "\n",
    "#             #HOG descriptor of a image\n",
    "\n",
    "#             # hog = cv2.HOGDescriptor()\n",
    "#             # image = hog.compute(image)\n",
    "\n",
    "#             #Shear transformation\n",
    "#             if args.shr == 1 :\n",
    "\n",
    "#                 pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
    "\n",
    "#                 pt1 = 5+10*np.random.uniform()-10/2\n",
    "#                 pt2 = 20+10*np.random.uniform()-10/2\n",
    "#                 pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
    "#                 shear = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "#                 image = cv2.warpAffine(image,shear,(col,row))\n",
    "#                 cv2.imwrite('shear.png',image)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            self.transform = transforms.Compose(\n",
    "                   [transforms.Resize((224,224)),\n",
    "                    # p.torch_transform(),\n",
    "                    transforms.ToTensor(),\n",
    "                    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                    ])\n",
    "\n",
    "\n",
    "            image = self.transform(PIL.Image.fromarray(image))\n",
    "\n",
    "        dictionary  ={}\n",
    "\n",
    "        # print (image.shape)\n",
    "        dictionary[\"image\"] = np.array(image,dtype = float)\n",
    "        dictionary[\"label\"] = float(image_label)\n",
    "        return dictionary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE_simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_simple, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(3*224*224, 400)\n",
    "        self.extra_layer = nn.Linear(400, 100)\n",
    "        self.extra_layer2 = nn.Linear(100, 100)\n",
    "        self.fc21 = nn.Linear(100, LATENT_DIM)\n",
    "        self.fc22 = nn.Linear(100, LATENT_DIM)\n",
    "        \n",
    "        self.fc3 = nn.Linear(LATENT_DIM, 100)\n",
    "        self.extra_layer_dec = nn.Linear(100, 100)\n",
    "        self.extra_layer_dec2 = nn.Linear(100, 400)\n",
    "        self.fc4 = nn.Linear(400, 3*224*224)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        h1 = self.relu(self.extra_layer(h1))\n",
    "        h1 = self.relu(self.extra_layer2(h1))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        h3 = self.relu(self.extra_layer_dec(h3))\n",
    "        h3 = self.relu(self.extra_layer_dec2(h3))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 3*224*224))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(reconstruced_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(reconstruced_x.view(-1, 3*224*224), x.view(-1, 3*224*224))\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Normalise by same number of elements as in reconstruction\n",
    "    KLD /= BATCH_SIZE * (3*224*224)\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_transform = Compose([ToTensor(), \n",
    "#                         ToPILImage(), \n",
    "#                         Resize((28,28)), \n",
    "#                         ToTensor()])\n",
    "train_directory ='data_road/training/image_2'\n",
    "test_directory = 'data_road/testing/image_2'\n",
    "train_set = KittiDataset(directory = train_directory, augment = False)\n",
    "correct_count = 0\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "# train_set = ImageFolder(root='train_set', transform=my_transform) #loading images from folder and resize them to 28x28\n",
    "# train_loader = DataLoader(train_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = VAE_simple()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "net.train() #set the model in the training mode (important for Dropout and BatchNorm)\n",
    "NUMBER_OF_IMAGES = len(train_loader)\n",
    "print (\"hi\")\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    print (epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data['image'].view(len(data[\"label\"]),3,224,224).float(),data['label'].float()\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        reconstructed_batch, mu, logvar = net(inputs)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(reconstructed_batch, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]*inputs.size(0)\n",
    "\n",
    "    print('Epoch %d, loss: %.3f' % (epoch + 1, running_loss / NUMBER_OF_IMAGES))\n",
    "                \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Let's see how our autoencoder reconstructs given images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "images = [0,0]\n",
    "\n",
    "output = net(Variable(train_loader.dataset[2000][0].unsqueeze(0)))\n",
    "images[0] = train_loader.dataset[2000][0] #original image\n",
    "images[1] = output[0].data.view(3,224,224) # reconstructed image\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(Variable(train_loader.dataset[3000][0].unsqueeze(0)))\n",
    "images[0] = train_loader.dataset[3000][0] #original image\n",
    "images[1] = output[0].data.view(3,224,224) # reconstructed image\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(Variable(train_loader.dataset[2500][0].unsqueeze(0)))\n",
    "images[0] = train_loader.dataset[2500][0] #original image\n",
    "images[1] = output[0].data.view(3,224,224) # reconstructed image\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images\n",
    "\n",
    "Now we generate images from random samples taken from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate 104 images and save it in 13x8 grid\n",
    "sample = Variable(torch.randn(104, LATENT_DIM))\n",
    "sample = net.decode(sample)\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "imshow(torchvision.utils.make_grid(sample.data.view(104, 3, 224, 224)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
